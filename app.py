# -*- coding: utf-8 -*-
"""App

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OPlr-4fOYhrQBCcQjIq1iTXOmiYLs9vB
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error

# -----------------------------------------------------------------------------
# 0. Helper Functions and Classes (from original script)
# -----------------------------------------------------------------------------

class DataPreprocessing:
    def __init__(self, data_column_name='IHK', feature_range=(0, 1)):
        self.data_column_name = data_column_name # To handle the specific column
        self.scaler = MinMaxScaler(feature_range=feature_range)
        self.feature_range = feature_range
        self._data_for_fitting_scaler = None # Store data used to fit scaler

    def check_missing_values(self, data_df):
        missing = data_df[[self.data_column_name]].isnull().sum()
        total_missing = missing.sum()
        return total_missing, missing[missing > 0]

    def fit_scaler(self, data_df):
        self._data_for_fitting_scaler = data_df[[self.data_column_name]].copy()
        self.scaler.fit(self._data_for_fitting_scaler)

    def normalize(self, data_df_column):
        # Expects a DataFrame column (e.g., data_df[[self.data_column_name]])
        return self.scaler.transform(data_df_column)

    def denormalize(self, normalized_data):
        # Expects a 2D array-like structure
        return self.scaler.inverse_transform(normalized_data)

def plot_acf_pacf_streamlit(series, lags=20, series_name="Series"):
    fig, axes = plt.subplots(2, 1, figsize=(10, 7))
    fig.patch.set_alpha(0) # Transparent background for figure
    axes[0].patch.set_alpha(0) # Transparent background for axes
    axes[1].patch.set_alpha(0)

    plot_acf(series, lags=lags, ax=axes[0], color='#0072B2', vlines_kwargs={"colors": '#0072B2'})
    axes[0].set_title(f'Autocorrelation Function (ACF) - {series_name}', color='#003B5C')
    axes[0].tick_params(colors='#003B5C')
    axes[0].xaxis.label.set_color('#003B5C')
    axes[0].yaxis.label.set_color('#003B5C')


    plot_pacf(series, lags=lags, ax=axes[1], method='ywm', color='#0072B2', vlines_kwargs={"colors": '#0072B2'})
    axes[1].set_title(f'Partial Autocorrelation Function (PACF) - {series_name}', color='#003B5C')
    axes[1].tick_params(colors='#003B5C')
    axes[1].xaxis.label.set_color('#003B5C')
    axes[1].yaxis.label.set_color('#003B5C')

    plt.tight_layout()
    return fig

def create_supervised_data(data_series, lags):
    df = pd.DataFrame(data_series)
    df.columns = ['value']
    for lag in lags:
        df[f'lag_{lag}'] = df['value'].shift(lag)
    df.dropna(inplace=True)
    X = df[[f'lag_{lag}' for lag in lags]].values
    y = df['value'].values
    return X, y, df.index # Return index for later alignment

class RBFNN:
    def __init__(self, n_centers, activation='gaussian'):
        self.n_centers = n_centers
        self.activation = activation
        self.centers = None
        self.weights = None
        self.spread = None

    def _gaussian(self, X_row, c): # Modified to handle row-wise for clarity if X is 1D
        distance = np.linalg.norm(X_row - c)
        if self.spread == 0: # Avoid division by zero
            return 1.0 if distance == 0 else 0.0
        return np.exp(-(distance**2) / (2 * (self.spread**2)))

    def _multiquadric(self, X_row, c): # Modified to handle row-wise
        return np.sqrt(np.linalg.norm(X_row - c) ** 2 + self.spread ** 2)

    def _calculate_activations(self, X):
        activations_list = []
        for i in range(X.shape[0]):
            row_activations = []
            for c_idx, c_val in enumerate(self.centers):
                if self.activation == 'gaussian':
                    row_activations.append(self._gaussian(X[i,:], c_val))
                elif self.activation == 'multiquadric':
                     row_activations.append(self._multiquadric(X[i,:], c_val))
            activations_list.append(row_activations)

        activations_matrix = np.array(activations_list)

        if activations_matrix.ndim == 1 and X.shape[0] > 0 : # Reshape if it became 1D
             activations_matrix = activations_matrix.reshape(X.shape[0], -1)
        elif X.shape[0] == 0: # Handle empty input X
            return np.empty((0, self.n_centers))

        return activations_matrix


    def fit(self, X, y):
        if X.shape[0] < self.n_centers:
            st.error(f"Jumlah data ({X.shape[0]}) lebih kecil dari jumlah center ({self.n_centers}). Tidak dapat melatih model KMeans. Kurangi jumlah center atau tambah data.")
            return False # Indicate failure

        kmeans = KMeans(n_clusters=self.n_centers, random_state=42, n_init='auto')
        kmeans.fit(X)
        self.centers = kmeans.cluster_centers_

        if self.n_centers > 1:
            center_distances = cdist(self.centers, self.centers, metric='euclidean')
            d_max = np.max(center_distances)
            self.spread = d_max / np.sqrt(2 * self.n_centers)
            if self.spread == 0 and self.n_centers > 1 : # handle cases where centers are identical
                self.spread = np.mean(np.std(X, axis=0)) if X.shape[0] > 0 else 1.0
                if self.spread == 0: self.spread = 1e-6 # small non-zero
                st.warning(f"Spread dihitung ulang karena d_max=0 (pusat cluster mungkin identik). Spread baru: {self.spread:.4f}")

        elif self.n_centers == 1:
            if X.ndim == 1:
                self.spread = np.std(X) if np.std(X) > 0 else 1.0
            else:
                self.spread = np.mean(np.std(X, axis=0))
            if self.spread == 0 : self.spread = 1e-6 # ensure spread is not zero, avoid division by zero
        else: # n_centers < 1
            st.error("Jumlah center harus minimal 1.")
            return False

        activations = self._calculate_activations(X)
        activations_with_bias = np.hstack([activations, np.ones((activations.shape[0], 1))])

        y_reshaped = np.array(y).reshape(-1, 1)
        self.weights = np.linalg.pinv(activations_with_bias) @ y_reshaped
        return True # Indicate success

    def predict(self, X):
        if self.centers is None or self.weights is None or self.spread is None:
            st.error("Model belum dilatih atau tidak berhasil dilatih.")
            return np.array([]) # Return empty if not fitted

        activations = self._calculate_activations(X)
        activations_with_bias = np.hstack([activations, np.ones((activations.shape[0], 1))])
        return activations_with_bias @ self.weights

def smape(y_true, y_pred):
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_pred) + np.abs(y_true))
    # Handle cases where denominator is zero
    # If both true and pred are zero, SMAPE for that point is 0.
    # If one is zero and other is not, SMAPE is 200% (or 2 in fraction).
    # Here, we avoid division by zero by replacing 0 in denominator with a small number,
    # or by handling cases. For simplicity, if denominator is 0, assume SMAPE for that point is 0 if num is also 0.

    smape_values = np.zeros_like(denominator)
    mask = denominator != 0
    smape_values[mask] = 2 * numerator[mask] / denominator[mask]

    # If true is 0 and pred is 0, num is 0, den is 0. Handled by zeros_like.
    # If true is X and pred is 0 (or vice versa, X!=0), num is |X|, den is |X|. So 2*|X|/|X| = 2.
    # The problem arises if y_true = 0 and y_pred = 0 simultaneously.
    # A common definition: if y_true and y_pred are both 0, the term is 0.
    # If only one is 0, the term is 2.

    # Let's refine for edge cases where both are zero or one is zero
    elements_smape = []
    for i in range(len(y_true)):
        yt = y_true[i]
        yp = y_pred[i]
        if abs(yt) < 1e-9 and abs(yp) < 1e-9: # Effectively both zero
            elements_smape.append(0.0)
        elif abs(yt) < 1e-9 or abs(yp) < 1e-9: # One is zero, other is not (implicitly)
            elements_smape.append(2.0) # Max error contribution for this point
        else:
            elements_smape.append(abs(yp - yt) / (abs(yp) + abs(yt)))

    return np.mean(elements_smape) * 100 * (2/2) # The factor of 2 is already in the loop if one is zero.
                                                # The original formula has 2 * mean(...)
                                                # My loop calculates abs(P-A)/(abs(P)+abs(A)). So multiply by 200.
    # Reverting to a more standard SMAPE that guards against zero denominators
    numerator = np.abs(y_true - y_pred)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2 # Note the /2 here

    # Create an array of zeros for results
    loss = np.zeros_like(y_true, dtype=float)

    # Mask for valid (non-zero denominator) calculations
    valid_mask = denominator != 0
    loss[valid_mask] = numerator[valid_mask] / denominator[valid_mask]

    # For cases where y_true and y_pred are both zero, error is 0 (already handled by loss=0 initialization)
    # For cases where one is zero and the other is not, the original formula implies error of 200% (or 2).
    # The formula used: 2 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100
    # Let's use the user's original SMAPE function for consistency, with a small epsilon for denominator
    epsilon = 1e-9 # To avoid division by zero if both are zero
    return 2 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + epsilon)) * 100


def predict_future(model, initial_data_normalized, lags, steps, normalizer):
    predictions_normalized = []
    current_input_normalized = initial_data_normalized.copy().flatten()

    for _ in range(steps):
        # Prepare input for model.predict: needs to be 2D array [1, num_lags]
        # The order of lags matters: if lags = [1, 2, 12], input should be [data_t-1, data_t-2, data_t-12]
        input_for_prediction = np.array([current_input_normalized[-lag] for lag in lags]).reshape(1, -1)

        pred_normalized = model.predict(input_for_prediction)

        # Ensure pred_normalized is a scalar or easily convertible
        if isinstance(pred_normalized, np.ndarray) and pred_normalized.ndim > 0:
            pred_normalized_scalar = pred_normalized[0,0] if pred_normalized.size > 0 else 0.0
        else:
            pred_normalized_scalar = float(pred_normalized) if pred_normalized is not None else 0.0

        predictions_normalized.append(pred_normalized_scalar)
        current_input_normalized = np.append(current_input_normalized, pred_normalized_scalar)

    denorm_predictions = normalizer.denormalize(np.array(predictions_normalized).reshape(-1, 1))
    return denorm_predictions.flatten()

# -----------------------------------------------------------------------------
# Streamlit App Setup
# -----------------------------------------------------------------------------
st.set_page_config(page_title="üìà Prediksi IHK RBFNN", layout="wide", initial_sidebar_state="collapsed")

# Custom CSS for theming
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# Create a dummy style.css if you want to use it, or embed CSS directly
# For simplicity, embedding some basic CSS here:
st.markdown("""
<style>
    /* Main app background */
    .stApp {
        background-color: #F0F8FF; /* AliceBlue - a very light cream/blue */
    }
    /* Main content area */
    .main .block-container {
        background-color: #FFFFFF; /* White for content cards */
        border-radius: 10px;
        padding: 2rem;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    /* Titles */
    h1, h2, h3, h4, h5, h6 {
        color: #0072B2; /* Dominant Blue */
    }
    /* Buttons */
    .stButton>button {
        background-color: #0072B2; /* Dominant Blue */
        color: white;
        border-radius: 5px;
        border: 1px solid #005A8C; /* Darker blue border */
        padding: 0.5rem 1rem;
    }
    .stButton>button:hover {
        background-color: #005A8C; /* Darker blue on hover */
        color: white;
    }
    .stButton>button:focus {
        outline: none !important;
        box-shadow: 0 0 0 0.2rem rgba(0,123,255,.5) !important; /* Blue focus ring */
    }
    /* Navigation Buttons */
    div[data-testid="stHorizontalBlock"] > div[data-testid^="stVerticalBlock"] > div[data-testid^="stButton"] > button {
        width: 100%;
        background-color: #E6F3FF; /* Lighter blue for nav */
        color: #0072B2;
        border: 1px solid #ADD8E6; /* Light blue border */
    }
    div[data-testid="stHorizontalBlock"] > div[data-testid^="stVerticalBlock"] > div[data-testid^="stButton"] > button:hover {
        background-color: #D0E8FF;
        color: #005A8C;
    }
    div[data-testid="stHorizontalBlock"] > div[data-testid^="stVerticalBlock"].nav-active > div[data-testid^="stButton"] > button {
        background-color: #0072B2 !important;
        color: white !important;
        font-weight: bold;
    }

    /* Sidebar styling (if used) */
    [data-testid="stSidebar"] {
        background-color: #D6EAF8; /* Light blue for sidebar */
        padding: 10px;
    }
    [data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {
        color: #005A8C; /* Darker blue for sidebar titles */
    }
    /* Input widgets */
    .stTextInput input, .stNumberInput input, .stSelectbox select {
        border-radius: 5px;
    }
    /* Dataframe styling */
    .stDataFrame {
        border: 1px solid #ADD8E6;
        border-radius: 5px;
    }

</style>
""", unsafe_allow_html=True)


# Initialize session state variables
if 'current_page' not in st.session_state:
    st.session_state.current_page = "Beranda"
if 'data_timeseries' not in st.session_state:
    st.session_state.data_timeseries = None
if 'file_uploaded' not in st.session_state:
    st.session_state.file_uploaded = False
if 'normalizer' not in st.session_state:
    st.session_state.normalizer = DataPreprocessing(data_column_name='IHK') # Initialize with default
if 'normalized_series' not in st.session_state:
    st.session_state.normalized_series = None
if 'significant_lags_input' not in st.session_state:
    st.session_state.significant_lags_input = "1, 2" # Default example
if 'trained_rbf_model' not in st.session_state:
    st.session_state.trained_rbf_model = None
if 'model_params' not in st.session_state: # Store params used for the trained model
    st.session_state.model_params = {}
if 'data_column_name' not in st.session_state:
    st.session_state.data_column_name = 'IHK' # Default, can be changed after upload
if 'date_column_name' not in st.session_state:
    st.session_state.date_column_name = 'Tanggal' # Default


# Navigation
st.markdown("<h1 style='text-align: center; color: #0072B2;'>üìà Aplikasi Prediksi IHK dengan RBFNN</h1>", unsafe_allow_html=True)
st.markdown("---")

nav_cols = st.columns(5)
pages = ["Beranda", "Upload File", "Pre-processing", "Pemodelan", "Prediksi"]
button_keys = ["nav_beranda", "nav_upload", "nav_preprocess", "nav_model", "nav_predict"]

active_style = """
    background-color: #0072B2 !important;
    color: white !important;
    font-weight: bold;
    border: 1px solid #005A8C !important;
"""
default_style = """
    background-color: #E6F3FF;
    color: #0072B2;
    border: 1px solid #ADD8E6;
"""

for i, page_name in enumerate(pages):
    is_active = (st.session_state.current_page == page_name)
    style = active_style if is_active else default_style

    # Disable pages if file not uploaded
    disabled_page = (page_name in ["Pre-processing", "Pemodelan", "Prediksi"]) and not st.session_state.file_uploaded

    if nav_cols[i].button(page_name, key=button_keys[i], disabled=disabled_page, use_container_width=True):
        st.session_state.current_page = page_name
        st.rerun() # Rerun to update the page content immediately

# Display message if trying to access disabled pages
if (st.session_state.current_page in ["Pre-processing", "Pemodelan", "Prediksi"]) and not st.session_state.file_uploaded:
    st.warning("‚õî Harap upload file CSV terlebih dahulu pada halaman 'Upload File' untuk mengakses halaman ini.")
    # Optionally, redirect to Upload File page or Beranda
    # st.session_state.current_page = "Upload File"
    # st.rerun()


# -----------------------------------------------------------------------------
# Page Implementations
# -----------------------------------------------------------------------------

def page_beranda():
    st.header("Selamat Datang di Aplikasi Prediksi IHK Surabaya")
    st.markdown("""
    Aplikasi ini menggunakan Radial Basis Function Neural Network (RBFNN) untuk melakukan prediksi Indeks Harga Konsumen (IHK).
    Navigasikan melalui menu di atas untuk memulai.
    """)

    st.subheader("Apa itu RBFNN?")
    st.markdown("""
    Radial Basis Function Neural Network (RBFNN) adalah jenis jaringan saraf tiruan yang menggunakan fungsi basis radial sebagai fungsi aktivasi.
    Jaringan ini biasanya memiliki tiga lapisan:
    1.  **Lapisan Input (Input Layer):** Menerima data input (misalnya, data IHK historis yang sudah di-lag).
    2.  **Lapisan Tersembunyi (Hidden Layer):** Terdiri dari neuron RBF. Setiap neuron menghitung fungsi basis radial (seperti Gaussian atau Multiquadric) berdasarkan jarak antara input dan pusat neuron tersebut. Jumlah neuron dan posisi pusatnya (centers) serta lebar (spread) dari fungsi RBF adalah parameter penting.
    3.  **Lapisan Output (Output Layer):** Menghasilkan output prediksi dengan melakukan kombinasi linear dari output neuron-neuron di lapisan tersembunyi. Bobot koneksi antara lapisan tersembunyi dan lapisan output dihitung selama proses pelatihan.

    **Kelebihan RBFNN:**
    -   Kemampuan belajar yang cepat.
    -   Struktur jaringan yang lebih sederhana dibandingkan beberapa jenis JST lainnya (misalnya MLP dengan banyak lapisan).
    -   Baik untuk aproksimasi fungsi dan klasifikasi.

    **Proses Pelatihan Umum RBFNN:**
    1.  **Penentuan Pusat (Centers):** Pusat-pusat fungsi RBF di lapisan tersembunyi ditentukan. Ini bisa dilakukan dengan algoritma clustering seperti K-Means pada data input, atau metode lainnya.
    2.  **Penentuan Lebar (Spread/Sigma):** Lebar atau spread dari setiap fungsi RBF ditentukan. Ini bisa dihitung berdasarkan jarak antar pusat atau heuristik lainnya.
    3.  **Penghitungan Bobot Output:** Bobot antara lapisan tersembunyi dan lapisan output dihitung, biasanya menggunakan metode least squares (pseudo-inverse) karena hubungan antara output lapisan tersembunyi dan output jaringan bersifat linear.
    """)

    # Using a more relevant image if possible, otherwise a generic NN diagram
    # Image from Wikimedia Commons (Public Domain or CC licensed for reuse)
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/RBF_network_architecture.svg/800px-RBF_network_architecture.svg.png",
             caption="Arsitektur Jaringan RBFNN (Sumber: Wikipedia)",
             use_column_width=True)
    st.markdown("<p style='font-size: smaller; text-align: center;'>Diagram oleh Mirca MAD (Mirko M.) - Own work, CC BY-SA 4.0</p>", unsafe_allow_html=True)


def page_upload_file():
    st.header("üì§ Upload File Data IHK")
    st.info("‚ÑπÔ∏è File harus berformat CSV, univariat (satu kolom data nilai), dan memiliki kolom 'Tanggal' serta kolom nilai (default 'IHK').")

    uploaded_file = st.file_uploader("Pilih file CSV", type="csv")

    if uploaded_file is not None:
        try:
            data = pd.read_csv(uploaded_file)
            st.success("üéâ File berhasil diupload!")

            st.subheader("Pilih Kolom Tanggal dan Data")
            available_columns = data.columns.tolist()

            col1, col2 = st.columns(2)
            date_col = col1.selectbox("Pilih Kolom Tanggal:", available_columns, index=available_columns.index(st.session_state.date_column_name) if st.session_state.date_column_name in available_columns else 0)
            value_col = col2.selectbox("Pilih Kolom Data (Nilai IHK):", available_columns, index=available_columns.index(st.session_state.data_column_name) if st.session_state.data_column_name in available_columns else 1 if len(available_columns)>1 else 0)

            st.session_state.date_column_name = date_col
            st.session_state.data_column_name = value_col

            # Prepare data
            data_timeseries = data[[date_col, value_col]].copy()
            data_timeseries[date_col] = pd.to_datetime(data_timeseries[date_col])
            data_timeseries.rename(columns={value_col: 'IHK_Value', date_col: 'Tanggal'}, inplace=True) # Standardize names internally
            data_timeseries.set_index('Tanggal', inplace=True)
            data_timeseries = data_timeseries[['IHK_Value']] # Ensure it's a DataFrame with one column

            st.session_state.data_timeseries = data_timeseries
            st.session_state.file_uploaded = True
            st.session_state.normalizer = DataPreprocessing(data_column_name='IHK_Value') # Re-initialize with correct column name


            st.subheader("Pratinjau Data (5 Baris Pertama)")
            st.dataframe(st.session_state.data_timeseries.head())

            st.subheader("Plot Data Time Series")
            fig, ax = plt.subplots(figsize=(12, 6))
            fig.patch.set_alpha(0)
            ax.patch.set_alpha(0)
            ax.plot(st.session_state.data_timeseries.index, st.session_state.data_timeseries['IHK_Value'], color='#0072B2', linewidth=2)
            ax.set_title(f'Data {st.session_state.data_column_name} Historis', color='#003B5C')
            ax.set_xlabel('Tanggal', color='#003B5C')
            ax.set_ylabel(st.session_state.data_column_name, color='#003B5C')
            ax.grid(True, linestyle='--', alpha=0.7)
            ax.tick_params(colors='#003B5C')
            st.pyplot(fig)

            st.subheader("Analisis Deskriptif")
            st.dataframe(st.session_state.data_timeseries['IHK_Value'].describe().to_frame().T)

            if st.button("Lanjut ke Pre-processing ‚û°Ô∏è", key="upload_next"):
                st.session_state.current_page = "Pre-processing"
                st.rerun()

        except Exception as e:
            st.error(f"‚ùå Terjadi kesalahan saat memproses file: {e}")
            st.session_state.file_uploaded = False
            st.session_state.data_timeseries = None
    else:
        st.session_state.file_uploaded = False # Reset if no file or file removed


def page_preprocessing():
    st.header("‚öôÔ∏è Pre-processing Data")
    if st.session_state.data_timeseries is None:
        st.warning("‚õî Silakan upload data terlebih dahulu di halaman 'Upload File'.")
        return

    data_ts = st.session_state.data_timeseries
    normalizer_obj = st.session_state.normalizer # This is an instance of DataPreprocessing

    st.subheader("1. Pengecekan Missing Values")
    total_missing, missing_details = normalizer_obj.check_missing_values(data_ts)
    if total_missing > 0:
        st.warning(f"‚ö†Ô∏è Terdapat {total_missing} missing value pada data:")
        st.write(missing_details)
        # Basic imputation strategy: ffill. User might want more options.
        data_ts_imputed = data_ts.fillna(method='ffill').fillna(method='bfill')
        if data_ts_imputed[[normalizer_obj.data_column_name]].isnull().sum().sum() > 0:
            st.error("Imputasi gagal menghilangkan semua missing values. Harap periksa data Anda.")
            return
        else:
            st.success("Missing values diimputasi menggunakan forward fill & backward fill.")
            st.session_state.data_timeseries = data_ts_imputed # Update data in session state
            data_ts = data_ts_imputed
    else:
        st.success("‚úÖ Tidak terdapat missing value pada data.")

    st.subheader("2. Normalisasi Data")
    try:
        # Fit the scaler with the (potentially imputed) data
        normalizer_obj.fit_scaler(data_ts)

        # Normalize the specific column
        normalized_values = normalizer_obj.normalize(data_ts[[normalizer_obj.data_column_name]])

        # Create a DataFrame for display
        normalized_df_display = data_ts.copy()
        normalized_df_display['Data Normalisasi'] = normalized_values
        normalized_df_display.rename(columns={normalizer_obj.data_column_name: 'Data Asli'}, inplace=True)

        st.markdown("Data dinormalisasi ke rentang [0, 1]. Berikut adalah contoh data asli dan data yang sudah dinormalisasi:")
        st.dataframe(normalized_df_display[['Data Asli', 'Data Normalisasi']].head())

        # Store normalized series (as a pandas Series for convenience) and the fitted normalizer
        st.session_state.normalized_series = pd.Series(normalized_values.flatten(), index=data_ts.index)
        st.session_state.normalizer = normalizer_obj # Store the fitted normalizer

        st.subheader("3. Identifikasi Lag Signifikan (ACF/PACF)")
        st.markdown("""
        Plot ACF (Autocorrelation Function) dan PACF (Partial Autocorrelation Function) membantu mengidentifikasi lag yang signifikan
        untuk model time series. Lag yang signifikan pada PACF sering digunakan untuk menentukan orde model AR (Autoregressive),
        yang relevan untuk input RBFNN.
        """)

        lags_to_plot = st.slider("Jumlah lag untuk plot ACF/PACF:", min_value=10, max_value=min(60, len(st.session_state.normalized_series)//3), value=24)
        fig_acf_pacf = plot_acf_pacf_streamlit(st.session_state.normalized_series, lags=lags_to_plot, series_name="Data Ternormalisasi")
        st.pyplot(fig_acf_pacf)

        st.markdown("Masukkan lag signifikan berdasarkan plot PACF (pisahkan dengan koma, contoh: 1,2,12):")
        lags_input_str = st.text_input("Lag Signifikan:", st.session_state.significant_lags_input, key="lags_input_preprocess")
        st.session_state.significant_lags_input = lags_input_str

        if st.button("Lanjut ke Pemodelan ‚û°Ô∏è", key="preprocess_next"):
            try:
                parsed_lags = [int(lag.strip()) for lag in lags_input_str.split(',') if lag.strip()]
                if not parsed_lags:
                    st.error("Harap masukkan setidaknya satu lag yang valid.")
                else:
                    st.session_state.current_page = "Pemodelan"
                    st.rerun()
            except ValueError:
                st.error("Format lag tidak valid. Harap masukkan angka yang dipisahkan koma (contoh: 1,2,3).")

    except Exception as e:
        st.error(f"‚ùå Terjadi kesalahan saat normalisasi atau plot ACF/PACF: {e}")


def page_pemodelan():
    st.header("üõ†Ô∏è Pemodelan RBFNN")
    if st.session_state.normalized_series is None or st.session_state.normalizer is None:
        st.warning("‚õî Data belum diproses. Silakan lengkapi tahap 'Pre-processing' terlebih dahulu.")
        return

    # --- Sidebar untuk Parameter ---
    st.sidebar.header("‚öôÔ∏è Parameter Model RBFNN")
    activation_fn = st.sidebar.selectbox("Fungsi Aktivasi:", ['gaussian', 'multiquadric'], key="activation_select")

    split_ratio_str = st.sidebar.selectbox("Rasio Data Training:Testing:", ["80:20", "70:30", "90:10"], index=0, key="split_ratio_select")
    split_map = {"90:10": 0.9, "80:20": 0.8, "70:30": 0.7}
    train_split_ratio = split_map[split_ratio_str]

    num_centers = st.sidebar.slider("Jumlah Center (Neuron RBF):", min_value=2, max_value=10, value=3, step=1, key="centers_slider") # Min 2 for spread calc

    st.sidebar.markdown("---")
    st.sidebar.subheader("Lag Input Model")
    lags_input_display = st.sidebar.text_input("Lag yang Digunakan (dari Pre-processing):",
                                               st.session_state.significant_lags_input,
                                               key="lags_display_model",
                                               help="Anda dapat mengubah lag di halaman Pre-processing jika diperlukan.")
    try:
        significant_lags = [int(lag.strip()) for lag in lags_input_display.split(',') if lag.strip()]
        if not significant_lags:
            st.error("Lag signifikan tidak valid atau kosong. Harap periksa input di halaman Pre-processing atau di sini.")
            return
        st.sidebar.info(f"Model akan menggunakan lag: {significant_lags}")
    except ValueError:
        st.error("Format lag tidak valid. Harap masukkan angka yang dipisahkan koma (contoh: 1,2,3).")
        return

    # --- Panel Utama ---
    st.subheader("Konfigurasi Model Saat Ini")
    col_conf1, col_conf2, col_conf3 = st.columns(3)
    col_conf1.metric("Fungsi Aktivasi", activation_fn.capitalize())
    col_conf2.metric("Rasio Split (Train)", f"{int(train_split_ratio*100)}%")
    col_conf3.metric("Jumlah Center", num_centers)
    st.markdown(f"**Lag Input yang Digunakan:** `{significant_lags}`")


    if st.button("Latih Model RBFNN üöÄ", key="train_model_button"):
        with st.spinner("Sedang melatih model RBFNN... Mohon tunggu üôè"):
            try:
                # 1. Create supervised data
                X_all, y_all, idx_all = create_supervised_data(st.session_state.normalized_series, significant_lags)
                if X_all.shape[0] == 0:
                    st.error("Gagal membuat data supervised. Kemungkinan karena lag terlalu besar atau data terlalu sedikit.")
                    return

                # 2. Split data
                split_index = int(train_split_ratio * len(X_all))
                X_train, X_test = X_all[:split_index], X_all[split_index:]
                y_train, y_test = y_all[:split_index], y_all[split_index:]
                idx_train, idx_test = idx_all[:split_index], idx_all[split_index:]

                if X_train.shape[0] == 0 or X_test.shape[0] == 0:
                    st.error(f"Pembagian data gagal. Data training atau testing kosong. (Train: {X_train.shape[0]}, Test: {X_test.shape[0]}). Coba rasio split atau lag yang berbeda.")
                    return

                # 3. Train RBFNN model
                rbf_model = RBFNN(n_centers=num_centers, activation=activation_fn)
                training_successful = rbf_model.fit(X_train, y_train)

                if not training_successful or rbf_model.weights is None:
                    st.error("‚ùå Gagal melatih model RBFNN. Periksa parameter atau data.")
                    st.session_state.trained_rbf_model = None
                    return

                st.session_state.trained_rbf_model = rbf_model
                st.session_state.model_params = {
                    'activation': activation_fn,
                    'split_ratio': train_split_ratio,
                    'n_centers': num_centers,
                    'lags': significant_lags,
                    'X_train': X_train, 'y_train': y_train, 'idx_train': idx_train, # Store for prediction page context
                    'X_test': X_test, 'y_test': y_test, 'idx_test': idx_test,
                    'full_normalized_series_for_pred': st.session_state.normalized_series # For initial data in predict_future
                }
                st.success("‚úÖ Model RBFNN berhasil dilatih!")

                # --- Display Results ---
                st.subheader("üìà Hasil Pelatihan & Evaluasi Model")

                col_res1, col_res2 = st.columns(2)
                col_res1.metric("Nilai Spread (œÉ) Model", f"{rbf_model.spread:.4f}" if rbf_model.spread is not None else "N/A")

                # Predictions (Normalized)
                y_train_pred_norm = rbf_model.predict(X_train)
                y_test_pred_norm = rbf_model.predict(X_test)

                # Denormalize for SMAPE and plotting
                normalizer = st.session_state.normalizer
                y_train_denorm = normalizer.denormalize(y_train.reshape(-1, 1))
                y_train_pred_denorm = normalizer.denormalize(y_train_pred_norm)
                y_test_denorm = normalizer.denormalize(y_test.reshape(-1, 1))
                y_test_pred_denorm = normalizer.denormalize(y_test_pred_norm)

                train_smape_val = smape(y_train_denorm, y_train_pred_denorm)
                test_smape_val = smape(y_test_denorm, y_test_pred_denorm)

                col_res1.metric("Train SMAPE", f"{train_smape_val:.2f}%")
                col_res2.metric("Test SMAPE", f"{test_smape_val:.2f}%")

                st.markdown("---")
                st.subheader("Visualisasi Hasil Prediksi (Data Asli)")

                fig_pred, ax_pred = plt.subplots(figsize=(14, 7))
                fig_pred.patch.set_alpha(0)
                ax_pred.patch.set_alpha(0)

                # Original full data for context (denormalized)
                full_original_data = st.session_state.data_timeseries[st.session_state.normalizer.data_column_name]
                ax_pred.plot(full_original_data.index, full_original_data.values, label='Data Asli (Historis)', color='gray', alpha=0.7, linestyle='--')

                # Training predictions
                ax_pred.plot(idx_train, y_train_denorm, label='Data Training (Asli)', color='blue', marker='.')
                ax_pred.plot(idx_train, y_train_pred_denorm, label='Prediksi Training', color='cyan', linestyle='--')

                # Testing predictions
                ax_pred.plot(idx_test, y_test_denorm, label='Data Testing (Asli)', color='green', marker='.')
                ax_pred.plot(idx_test, y_test_pred_denorm, label='Prediksi Testing', color='orange', linestyle='--')

                ax_pred.set_title(f'Perbandingan Data Asli vs Prediksi ({st.session_state.data_column_name})', color='#003B5C')
                ax_pred.set_xlabel('Tanggal', color='#003B5C')
                ax_pred.set_ylabel(st.session_state.data_column_name, color='#003B5C')
                ax_pred.legend(loc='upper left')
                ax_pred.grid(True, linestyle='--', alpha=0.7)
                ax_pred.tick_params(colors='#003B5C')
                st.pyplot(fig_pred)

            except Exception as e:
                st.error(f"‚ùå Terjadi kesalahan saat melatih model: {e}")
                import traceback
                st.error(traceback.format_exc()) # For debugging
                st.session_state.trained_rbf_model = None

    if st.session_state.trained_rbf_model is not None:
        st.markdown("---")
        if st.button("Lanjut ke Prediksi Masa Depan üîÆ", key="model_next"):
            st.session_state.current_page = "Prediksi"
            st.rerun()


def page_prediksi():
    st.header("üîÆ Prediksi IHK 5 Bulan ke Depan")

    if st.session_state.trained_rbf_model is None or not st.session_state.model_params:
        st.warning("‚õî Model belum dilatih. Silakan latih model di halaman 'Pemodelan' terlebih dahulu.")
        return

    model_to_use = st.session_state.trained_rbf_model
    params_used = st.session_state.model_params
    normalizer = st.session_state.normalizer

    st.subheader("Menggunakan Model yang Dilatih dengan Parameter:")
    param_df_data = {
        "Parameter": ["Fungsi Aktivasi", "Rasio Split (Train)", "Jumlah Center", "Lag Input"],
        "Nilai": [
            params_used['activation'].capitalize(),
            f"{int(params_used['split_ratio']*100)}%",
            params_used['n_centers'],
            str(params_used['lags'])
        ]
    }
    st.table(pd.DataFrame(param_df_data))


    with st.spinner("Melakukan prediksi 5 bulan ke depan..."):
        try:
            # Prepare initial data for multi-step prediction
            # Use the end of the full normalized series
            full_normalized_series = params_used['full_normalized_series_for_pred']

            if not params_used['lags']: # Should not happen if validated before
                st.error("Tidak ada lag yang ditentukan untuk prediksi.")
                return

            max_lag = max(params_used['lags'])
            if len(full_normalized_series) < max_lag:
                st.error(f"Data historis ternormalisasi tidak cukup untuk lag terbesar ({max_lag}). Panjang data: {len(full_normalized_series)}")
                return

            initial_data_norm = full_normalized_series[-max_lag:].values # Ensure it's numpy array

            # Predict 5 steps ahead
            future_predictions_denorm = predict_future(
                model=model_to_use,
                initial_data_normalized=initial_data_norm,
                lags=params_used['lags'],
                steps=5,
                normalizer=normalizer
            )

            # Generate future dates
            last_date_historis = st.session_state.data_timeseries.index[-1]
            future_dates = pd.date_range(
                start=last_date_historis + pd.DateOffset(months=1),
                periods=5,
                freq='MS'  # Month Start
            )

            future_df = pd.DataFrame({
                'Tanggal': future_dates,
                f'Prediksi {st.session_state.data_column_name}': future_predictions_denorm
            })

            st.subheader("Hasil Prediksi 5 Bulan ke Depan:")
            st.dataframe(future_df.style.format({'Tanggal': lambda t: t.strftime('%Y-%m-%d'),
                                                 f'Prediksi {st.session_state.data_column_name}': "{:.2f}"}))

            # Visualization
            st.subheader("Visualisasi Prediksi vs Data Historis")
            fig_future, ax_future = plt.subplots(figsize=(14, 7))
            fig_future.patch.set_alpha(0)
            ax_future.patch.set_alpha(0)

            original_data_series = st.session_state.data_timeseries[normalizer.data_column_name]
            ax_future.plot(original_data_series.index, original_data_series.values, label='Data Historis Asli', color='#0072B2')
            ax_future.plot(future_dates, future_predictions_denorm, label='Prediksi 5 Bulan ke Depan', color='red', marker='o', linestyle='--')

            ax_future.set_title(f'Prediksi {st.session_state.data_column_name} 5 Bulan ke Depan', color='#003B5C')
            ax_future.set_xlabel('Tanggal', color='#003B5C')
            ax_future.set_ylabel(st.session_state.data_column_name, color='#003B5C')
            ax_future.legend()
            ax_future.grid(True, linestyle='--', alpha=0.7)
            ax_future.tick_params(colors='#003B5C')
            st.pyplot(fig_future)

        except Exception as e:
            st.error(f"‚ùå Terjadi kesalahan saat melakukan prediksi masa depan: {e}")
            import traceback
            st.error(traceback.format_exc())


# -----------------------------------------------------------------------------
# Main App Logic: Page Routing
# -----------------------------------------------------------------------------
if st.session_state.current_page == "Beranda":
    page_beranda()
elif st.session_state.current_page == "Upload File":
    page_upload_file()
elif st.session_state.current_page == "Pre-processing":
    if st.session_state.file_uploaded:
        page_preprocessing()
    # Message about uploading file is handled globally
elif st.session_state.current_page == "Pemodelan":
    if st.session_state.file_uploaded:
        page_pemodelan()
elif st.session_state.current_page == "Prediksi":
    if st.session_state.file_uploaded:
        page_prediksi()

st.markdown("---")
st.markdown("<p style='text-align: center; font-size: small; color: #005A8C;'>Aplikasi Prediksi IHK Surabaya - Dibuat dengan Streamlit</p>", unsafe_allow_html=True)